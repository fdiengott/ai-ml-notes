Rectified Linear Unit
An activation function for neural networks that take on the following properties
`g(z) = max(0,z)`

if $z < 0$, $g(z) = 0$
If $z\geq0$, $g(z) = z$ 