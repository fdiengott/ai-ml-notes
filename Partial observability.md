observations are not assumed to be [[Markov decision process|markovian]] - More history would help it improve its ability to make more precise probabilities

partially observable Markov decision process (POMDP)
this is the common case
the environment may be markov, but the agent does not know it

